{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de frases chequeables usando Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este problema se intentará usar [Beto](https://github.com/dccuchile/beto) y HuggingFace. Especialmente se sigue este [ejemplo](https://huggingface.co/transformers/custom_datasets.html#seq-imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "#!wget https://users.dcc.uchile.cl/~jperez/beto/cased_2M/pytorch_weights.tar.gz \n",
    "#!wget https://users.dcc.uchile.cl/~jperez/beto/cased_2M/vocab.txt \n",
    "#!wget https://users.dcc.uchile.cl/~jperez/beto/cased_2M/config.json \n",
    "#!tar -xzvf pytorch_weights.tar.gz\n",
    "#!mv config.json pytorch/.\n",
    "#!mv vocab.txt pytorch/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForMaskedLM, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at pytorch/ were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"pytorch/\", do_lower_case=False)\n",
    "model = BertForMaskedLM.from_pretrained(\"pytorch/\")\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASK 0 : ['ignorancia', 'guerra', 'pobreza', 'muerte', 'violencia']\n",
      "MASK 1 : ['país', 'tiempo', 'pueblo', 'mundo', 'planeta']\n"
     ]
    }
   ],
   "source": [
    "text = \"[CLS] La [MASK] es el problema de nuestro [MASK] [SEP]\"\n",
    "masked_indxs = (2,8)\n",
    "\n",
    "tokens = tokenizer.tokenize(text)\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokens)\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "predictions = model(tokens_tensor)[0]\n",
    "\n",
    "for i,midx in enumerate(masked_indxs):\n",
    "    idxs = torch.argsort(predictions[0,midx], descending=True)\n",
    "    predicted_token = tokenizer.convert_ids_to_tokens(idxs[:5])\n",
    "    print('MASK',i,':',predicted_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from constants import POS_TAGGED_FOLDER\n",
    "\n",
    "\n",
    "def get_tagged_sentences(folder):\n",
    "    # Load all the tagged sentences included in the .pickle files \n",
    "    parsed_sentences = []\n",
    "    for filename in glob.glob(folder + '*.pickle'):\n",
    "        with open(filename, 'rb') as tagged_file:\n",
    "            parsed_sentences = parsed_sentences + pickle.load(tagged_file, encoding=\"bytes\")\n",
    "    return parsed_sentences\n",
    "\n",
    "tagged_sentences = get_tagged_sentences(POS_TAGGED_FOLDER)\n",
    "data = [{'sentence': item[b'sentence'].decode('utf8').lower(), 'target': item[b'classification'].decode('utf8')} for item in tagged_sentences]\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': '\\ufeffdiscurso de la presidenta cristina fernández de kirchner en la inauguracion del 133° periodo de sesiones ordinarias del congreso nacional',\n",
       " 'target': 'non-fact-checkable'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿discurso de la presidenta cristina fernández ...</td>\n",
       "      <td>non-fact-checkable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>muy buenos días a todos y todas</td>\n",
       "      <td>non-fact-checkable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vengo una vez más a cumplir con lo dispuesto p...</td>\n",
       "      <td>non-fact-checkable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>y la verdad que quiero comenzar dando cuenta d...</td>\n",
       "      <td>non-fact-checkable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>el día viernes 27 pude leer un tuit en la cuen...</td>\n",
       "      <td>non-fact-checkable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence              target\n",
       "0  ﻿discurso de la presidenta cristina fernández ...  non-fact-checkable\n",
       "1                    muy buenos días a todos y todas  non-fact-checkable\n",
       "2  vengo una vez más a cumplir con lo dispuesto p...  non-fact-checkable\n",
       "3  y la verdad que quiero comenzar dando cuenta d...  non-fact-checkable\n",
       "4  el día viernes 27 pude leer un tuit en la cuen...  non-fact-checkable"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-3ba6a057844a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m '''\n\u001b[1;32m     17\u001b[0m \u001b[0;31m###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m  \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'fact-checkable'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "'''\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(df, df['target']):\n",
    "    strat_train_set = df.loc[train_index]\n",
    "    strat_test_set = df.loc[test_index]\n",
    "\n",
    "train_texts = strat_train_set.drop(['target'], axis=1).astype(str)\n",
    "train_labels = strat_train_set['target'].values.tolist()\n",
    "\n",
    "test_texts = strat_test_set.drop(['target'], axis=1).values.tolist()\n",
    "test_labels = strat_test_set['target'].values.tolist()\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)\n",
    "'''\n",
    "###\n",
    "X = [e['sentence'] for e in data]\n",
    "y = [0  if e['target'] == 'fact-checkable' else 1 for e in data]\n",
    "\n",
    "sentences = [\"[CLS] \" + e['sentence'] + \" [SEP]\" for e in data]\n",
    "labels = [0  if e['target'] == 'fact-checkable' else 1 for e in data]\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(X, y, test_size=.2)\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['¿por qué protestan? les digo',\n",
       " 'por eso el gran desafío fue mantener políticas públicas activas y aumentar las que ya habíamos desplegado para precisamente poder superar toda esta crisis',\n",
       " 'stolbizer- creo posible y necesario establecer acuerdos',\n",
       " ' la república argentina es el único país que ha descendido en forma negativa su deuda externa en todo el mundo',\n",
       " 'este adelanto en materia de transplante es también patrimonio del parlamento argentino a partir de la aprobación de la ley del donante presunto']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class ChqDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = ChqDataset(train_encodings, train_labels)\n",
    "val_dataset = ChqDataset(val_encodings, val_labels)\n",
    "test_dataset = ChqDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at pytorch/ were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at pytorch/ and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='775' max='775' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [775/775 04:12, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.680541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.680453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.620086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.559473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.583552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.521176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.452430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.367741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.369752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.361647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.346413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.384587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.234018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.341694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.352852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.176521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.175262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.281357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.184632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.363698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.192397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.196714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.273158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.329172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.253615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.193625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.152853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.287333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.336805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.151416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.202657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.043102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.182343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.107600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.196217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.100383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.200086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.082635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.233781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.154616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.320234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.183944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.144470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.152608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.184438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.183208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.079955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.022195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.086252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.116829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.054254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.064793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.143614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.263046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.117714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.057156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.264734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.175836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.078848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.078896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.003284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.019269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.019980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.025900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.046706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.016994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.009203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.011520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.003918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.002414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.004076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.048848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.043687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.001489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.000491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.000508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=775, training_loss=0.1933819776965726)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=5,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"pytorch/\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset,             # evaluation dataset\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('qsch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='16' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 08:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.46729370951652527,\n",
       " 'eval_accuracy': 0.9142394822006472,\n",
       " 'eval_f1': 0.9284750337381916,\n",
       " 'eval_precision': 0.9373297002724795,\n",
       " 'eval_recall': 0.9197860962566845,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_texts = ['hay más de 25 millones de trabajadores que están registrados', \n",
    "              'hay más de 50 millones de trabajadores que están registrados', \n",
    "              'discurso de la presidenta cristina fernández de kirchner en la inauguracion del 133° periodo',\n",
    "             'vamos a otorgar un subsidio de 15 mil pesos por cada nuevo empleo registrado durante doce meses',\n",
    "              'prometo bajar la inflación a un 10% en el 2021',\n",
    "             'se le saca a la Ciudad el 12% del presupuesto',\n",
    "             ]\n",
    "demo_labels = [0, 0, 1, 1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_encodings = tokenizer(demo_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(demo_encodings.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_dataset = ChqDataset(demo_encodings, demo_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 4.438871 , -3.965041 ],\n",
       "       [ 4.4410357, -3.9678428],\n",
       "       [-3.9221334,  3.6707048],\n",
       "       [ 2.477028 , -1.8974282],\n",
       "       [ 3.7844305, -3.4295647],\n",
       "       [ 4.4204555, -3.960571 ]], dtype=float32), label_ids=array([0, 0, 1, 1, 0, 0]), metrics={'eval_loss': 0.7314813137054443, 'eval_accuracy': 0.8333333333333334, 'eval_f1': 0.6666666666666666, 'eval_precision': 1.0, 'eval_recall': 0.5})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.predict(demo_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hay más de 25 millones de trabajadores que están registrados',\n",
       " 'hay más de 50 millones de trabajadores que están registrados',\n",
       " 'discurso de la presidenta cristina fernández de kirchner en la inauguracion del 133° periodo',\n",
       " 'vamos a otorgar un subsidio de 15 mil pesos por cada nuevo empleo registrado durante doce meses',\n",
       " 'se le saca a la Ciudad el 12% del presupuesto']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without labels\n",
    "class ChqInferenceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, total_items):\n",
    "        self.encodings = encodings\n",
    "        self.total_items = total_items\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        #item['labels'] = torch.tensor(self.labels[idx])\n",
    "        print(item)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-749d77a67c82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdemo_encodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdemo_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnolabel_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChqInferenceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdemo_encodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdemo_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnolabel_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "demo_encodings = tokenizer(demo_texts, truncation=True, padding=True)\n",
    "nolabel_dataset = ChqInferenceDataset(demo_encodings, len(demo_texts))\n",
    "output = trainer.predict(nolabel_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.3871017, -3.7961414],\n",
       "       [ 3.3651884, -3.7773092],\n",
       "       [-3.2432277,  3.7316933],\n",
       "       [-1.8270873,  3.0422065],\n",
       "       [ 3.815342 , -4.118779 ]], dtype=float32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección de inferencia a partir de la carga del modelo pre-entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_classification = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"./qsch\",\n",
    "    tokenizer=\"dccuchile/bert-base-spanish-wwm-cased\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9992413520812988},\n",
       " {'label': 'LABEL_0', 'score': 0.9992098212242126},\n",
       " {'label': 'LABEL_1', 'score': 0.9990658760070801},\n",
       " {'label': 'LABEL_1', 'score': 0.9923797249794006},\n",
       " {'label': 'LABEL_0', 'score': 0.9988777041435242},\n",
       " {'label': 'LABEL_0', 'score': 0.9996417760848999},\n",
       " {'label': 'LABEL_1', 'score': 0.9501869082450867},\n",
       " {'label': 'LABEL_0', 'score': 0.9963929057121277},\n",
       " {'label': 'LABEL_1', 'score': 0.9972434639930725},\n",
       " {'label': 'LABEL_1', 'score': 0.985137403011322},\n",
       " {'label': 'LABEL_0', 'score': 0.9995606541633606},\n",
       " {'label': 'LABEL_1', 'score': 0.9986720085144043},\n",
       " {'label': 'LABEL_1', 'score': 0.999411404132843},\n",
       " {'label': 'LABEL_1', 'score': 0.9993310570716858},\n",
       " {'label': 'LABEL_1', 'score': 0.9992738366127014}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_claims = [\n",
    "    'hay más de 25 millones de trabajadores que están registrados', \n",
    "    'hay más de 50 millones de trabajadores que están registrados', \n",
    "    'discurso de la presidenta cristina fernández de kirchner en la inauguracion del 133° periodo',\n",
    "    'vamos a otorgar un subsidio de 15 mil pesos por cada nuevo empleo registrado durante doce meses',\n",
    "    'prometo bajar la inflación a un 10% en el 2021',\n",
    "    'se le saca a la Ciudad el 12% del presupuesto',\n",
    "    'no es cierto que vamos a devaluar en enero',\n",
    "    'Guzmán está tomando deuda al 17%',\n",
    "    'La única posibilidad de Argentina de iniciar la recuperación es crear las condiciones para impulsar la inversión, generadora de nuevos puestos de trabajo bajo regímenes más modernos y tan justos como los vigentes',\n",
    "    'Y cuando decimos que queremos bajar el déficit a cuatro puntos y medio –de los 9 que seguramente tendremos este año–, nos llaman ajustadores',\n",
    "    'Hoy se consume la misma energía para producción industrial que se consumía el 19 de marzo. Y el consumo es más alto',\n",
    "    'Yo no comparto la mirada de muchos que dicen que esto es un ajuste sobre los jubilados porque en verdad se basa en dos puntos: la variación de los salarios y la recaudación, que es importante porque si no recaudás, no podemos pagar',\n",
    "    'Alberto qué recuerdos tienes de la última vez que te visitó Diego, en enero y cuál es el recuerdo del primer contacto que tenés con Diego.',\n",
    "    'Yo creo que, en verdad, todos los argentinos estamos en deuda con él, porque son esos hombres que… bueno con vos pasa un poco lo mismo, son esos hombres que sólo nos han dado alegría. ',\n",
    "    '¿Cómo se hace – Alberto - para convivir siendo el presidente de todos los argentinos, el hincha, el hombre común, en un momento para desempeñar tantos roles, porque por un lado hay una cosa del protocolo, pero surge el hincha, la emoción, del tipo común, cómo se hace para manejar eso?',\n",
    "]\n",
    "text_classification(eval_claims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus track: test de un modelo de QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e33c695d125344c88f4937cc8e437787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=465.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38bccadd83e1477683a2e91f8965391e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=439457860.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0834fd9fd8254cf38731370f550d3486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=242349.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e15c39db10448a49c7f689390333284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=112.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e7421ac0f146bca945e3e5f8c1c145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=135.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nlp = pipeline(\n",
    "    'question-answering', \n",
    "    model='mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es',\n",
    "    tokenizer=(\n",
    "        'mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es',  \n",
    "        {\"use_fast\": False}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.youtube.com/watch?v=yA_IDTcoj-Q\n",
    "#lo pasamos por el desgrabador y obtenemos el siguiente texto\n",
    "context = r\"\"\"\n",
    "hoy vamos a dar la lección 1 sociología y vida cotidiana vamos a repasar los principales términos de los autores de la lección 1 en primer lugar tenemos a márquez donde los términos más importantes lo que nosotros tenemos que destacar de este autor es que naturalizamos lo social es decir que tenemos una actitud irreflexiva frente a nuestras conductas cotidianas el segundo actor fue meals que nos habló de imaginación sociológica que es la invasión de imaginación sociológica bueno es una cualidad que permite comprender la relación entre problema e inquietud y entre biografía e historia he aquí que tenemos los principales términos que tenemos que identificar de este autor en lo que respecta a la sociedad la historia de la sociedad y la biografía individual lo que es una inquietud y lo que es un problema recordemos que inquietud hace referencia a un asunto privado que ocupa a una sola persona y un problema es un asunto público que refiere a varias personas por ejemplo el hecho del desempleo si una sola persona en la sociedad no tiene trabajo ese es un asunto privado es una inquietud pero si el 18 por ciento de la de las personas en edad laboral de una sociedad no tienen trabajo pasa a ser un asunto público con respecto a elías elías va a hablar sobre las dificultades en nuestro idioma para pensar sociológicamente a través de la cosificación que es una deshumanización de figuras sociales que nos lleva a la metafísica de esas figuras y que nuestro lenguaje está basado en un modelo de ciencias naturales y del pensamiento mágico mítico y basado básicamente en un modelo de voz céntrico donde las fantasías ocupan un lugar errado en la vida de los hombres y va a proponer el modelo de relaciones de interdependencia donde todos estamos conectados en la sociedad en el trabajo de la sociología debe ser ampliar y hacer más confiable la comprensión de los elementos o activos por su parte heller nos va a hablar de la vida cotidiana es decir la vida cotidiana es un conjunto de actividades que implican al mismo tiempo la reproducción individual y social es jerárquica por eso habla de un regimiento de la vida es heterogénea ya que es el ya que el medio de superación a la particularidad es la homogenización y habla sobre el papel que juega la ultra generalización en nuestra vida cotidiana a través de los juicios provisionales y los prejuicios y va a mencionar también la extra la extraña acción de la vida cotidiana que proviene de la cristalización de las características de la vida cotidiana que reducen el margen de movimiento y conciencia de los individuos va a mencionar también la ética que tiene que sirve para el veto de ciertas conductas y también para la transformación quiere decir que el ser que las personas son al mismo tiempo particular y específico el medio recordemos para de superación de la particularidad hacia la especificidad es la homogenización de la vida cotidiana con respecto a berger y lukman van a ver la sociedad desde dos puntos de vista primero la sociedad como realidad objetiva hablar de la institucionalización va a decir que el orden social es un producto humano y aparece cada vez que se da una tipificación recíproca de acciones habitual izadas por tipos de actores esto hay que recordarlo es bastante importante con respecto a la institucionalización estos son los principales temas y puntos que tocan bergara bergara y luminosos principales conceptos institucionalización roles sedimentación el legitimación por otro lado la sociedad con realidad subjetiva va a hablar sobre la socialización primaria que es la que se da en la primera etapa de la vida de la persona la socialización secundaria que es la siguiente como es el mantenimiento y transformación de la realidad y va a mencionar también algo sobre las teorías de la identidad edad 23 perspectivas sociológicas si quieres recibir el resumen completo tanto del primer parcial como del segundo o ambos para preparar el final solamente tienes que suscribirte a mi canal y dejarme un comentario para que te pueda enviar el email en formato pdf con este resumen vamos a comenzar tenemos tres auto autores en esta unidad número dos el primero de ellos es urgen que va a hablar principalmente su punto central va a ser hecho social que es un hecho social y va a partir de la de la sociología objetivista su sociología va a ser objetivista porque también porque exige que el sociólogo explique las causas externas que llevan a los individuos a actuar y que va a decir sobre un hecho social va a ser que son cosas va a hablar de corriente opinión iba a hablar de que la realidad social es independiente de la voluntad de los individuos y en estos son los principales términos de este autor con respecto al segundo autor que se nos presenta en esta unidad que es marx que se puede profundizar mucho más pero estos son sus principales términos que nos van a tomar en el examen el primero de ellos es la producción sobre la producción más simples la producción es de individuos que en sociedad va a decir que el proceso de trabajo es natural y social y su principal termino con relación la producción va a ser la plusvalía plusvalía también va a hablar sobre consumo y producción sobre distribución cambio y producción y sobre el capitalismo que va a decir que es un tipo de organización social cuyo objetivo es la acumulación de riquezas y continua reproducción de capital y que la expansión e integración constante del mercado exterior es una gran unidad económica más todo esto más el creciente aumento de la productividad del trabajo por la permanente innovación tecnológicos son los mecanismos que garantizan su continuidad ciclina e irving van a retomar el trabajo de marks y van a hablar van a mencionar precisamente estos términos van a hablar con respecto a la religión y las condiciones seculares principalmente del judaísmo y les va a decir que para evitar la discriminación y la destrucción deben emanciparse del comercio del dinero y que las relaciones de propiedad es el punto de partida de la teoría de clases beber por su parte va a hablar en esta en esta unidad principalmente de acción social la acusación es una acción en donde encendido aumentado por su sujeto está referido a la conducta de otras personas a la voluntad de otros por eso es habla de un sentido subjetivo sentido subjetivo no toda clase de contacto entre personas entre hombres tiene carácter social y la acción social relacionado también con lo que es dominación va a decir que es racional con arreglo a fines racional con arreglo a valores afectiva o tradicional y el método de la sociología comprensión es racionalista para medio ya que exige el sociólogo intérprete en sentido a partir del cual las personas orientan su acción bien vamos a esta unidad que es poder vamos a revisar a tres autores el primero de ellos al tu ser va a hablar del poder con respecto a la reproducción de las condiciones de producción primero hablar de la reproducción de los medios de producción a lo cual lo explica a vagamente y no le da demasiada importancia ya que es básicamente la obtención de los materiales para producir pero si le dan mayor importancia a la reproducción de las relaciones de producción existente y en la reproducción de las fuerzas productivas con respecto a la reproducción de las relaciones de producción existentes tenemos que decir que éstas están aseguradas por la acción de los aparatos de estado que terminan siendo relaciones de explotación y con respecto a la reproducción de las fuerzas productivas en la reproducción de la fuerza de trabajo será fuera de la empresa como a través del salario que le permite al trabajador vivir y satisfacer sus necesidades y a través de la calificación laboral esta planificación laboral son habilidades que se adquieren en el sistema educativo a través de los años y principalmente la sumisión al sistema por su parte va a decir que el estado es un aparato represivo que permite a la clase dominante asegurar su dominación sobre la clase trabajadora para someterlo al proceso de exploración de la plusvalía como a través de los aparatos represivos del estado y los y del aparato ideológico del estado los aparatos represivos son por ejemplo la policía el ejército la administración que funciona mediante la violencia de los aparatos ideológicos son por ejemplo la escuela la familia iglesia que funcionan mediante la ideología bien estos son los principales términos principales conceptos de este autor en relación al poder el segundo autor es beber el primero va a definir algunos términos que son importantes por ejemplo poder que es la imposición de la propia voluntad ya sea contra toda resistencia lo que es la dominación la disciplina y la asociación de dominación ellos son básicamente alguno de los principales términos que define ver quiero hablar son distintos tipos de dominación legítima el primero la industria racional la tradicional el carismático y nos va a decir que toda dominación requiere de un cuadro administrativo el primer tipo de dominación la dominación racional tiene ciertas características que enumera por ejemplo un ejercicio continuado sujeto a la ley la competencia la jerarquía administrativa reglas técnicas o normas y los funcionarios no son los propietarios de los medios materiales de administración y tampoco existe la apropiación de los cargos en el cuadro administrativo es un cuadro administrativo burocrático con respecto a la dominación tradicional nos va a decir que su legitimidad se basa en la santidad de ordenaciones y poderes de mando elevados de tiempos lejanos no se obedece a disposiciones sino a la persona los mandatos de las personas hoy legítimo por la fuerza la tradición y son legítimos por arbitrio libre del señor este tipo de dominación se ve básicamente monarquías y la dominación carismática en la que en la que mayor énfasis hace su estudio lo que es la que más le interesó a este autor este tipo de dominación es decirle carisma es una cualidad extraordinaria y se la considera esta para la persona que ejerce este tipo de dominación se la considera en posesión de fuerzas sobre humanas el reconocimiento se mantiene por corroboración es decir aquel que ejerce el dominio de tipo carismático debe mostrar que en verdad tiene estas fuerzas sobre humanas que generan el bienestar entro en todos los nominados el proceso de comunicaciones de carácter emotivo se opone a la dominación tradicional y racional y el carisma puro es específicamente extraño a la economía su cuadro administrativo está formado por servidores ligados a la autoridad en virtud de la lealtad personal y tiene un carácter extraordinario y revolucionario está este tipo de dominación también debe utilizarse debe racionalizarse ya que no se puede constantemente a ejercer este tipo de dominación como se racionaliza bueno por interés de la comunidad y por interés del cuadro administrativo al mantener su posición en caso de que desaparezca la persona portadora de carisma se hace una nueva búsqueda por revelación o por designación hecha por el que portaba el carisma por una designación echarle por el cuadro administrativo o se hace una búsqueda dentro de la familia en torno a los herederos de la persona carismática ya que se relaciona con la sangre fútbol por su parte cuando habla hable sobre poder nos va a decir que el sistema de poder de la monarquía excesivamente oneroso lo que hacía que el poder político fuera muy discontinuo por ello la burguesía y la monarquía instalaron una nueva forma de poder basada en el derecho donde ya no existe un solo poder sino que existen varios y el poder viene desde abajo y atraviesa toda relación social surgen las técnicas políticas como la disciplina la educación y el poder se ejerce en espacios cotidianos como la escuela una familia que se cambia la anátomo política por la videopolítica lanata como política se ejerce sobre los cuerpos en cambio la vida política se ejerce sobre la población la primera de ellas prescribe a partir de nuevas preexistentes las segundas reglas y normas fijadas y el poder deja de ser jurídico para hacer materialista va a hablar también sobre la delincuencia que tiene para este autor posee utilidad económica y el peligro interno es una de las condiciones de aceptabilidad del control vamos a ver los autores que se nos presentan en la unidad 4 el primero de ellos es le fevre con respecto a la ideología va a decirnos que es un reflejo invertido mutilado y deformado de lo real va a hablar también de la praxis donde intervienen mediante las mediante la cooperación y persuasión se convierte en el lenguaje y legitima las relaciones del poder esto es lo que nos dice con respecto a ideologías y estos son los principales conceptos que tenemos que tener en cuenta ideología y praxis y la ideología tiene un carácter doble por un lado son generales y especulativas y por otro lado representan intereses particulares con respecto al primer carácter general y especulativas en este lugar y actúa la coerción y la persuasión y se puede observar la transparencia de la ideología en segundo lugar cuando la iv de la gente presente intereses particulares se asume la parte de la debilidad humana y se ve la opacidad de la ideología el segundo autor alto observó hablar sobre ideología general e ideologías particulares va a ser esta distinción de la ideología general nos va a decir que no tiene historia que es eterna y nos va a decir que hay una garantía de que todo está bien como está con la condición de que los sujetos reconozcan lo que son y se conduzcan en consecuencia con respeto energía particular no hace que tiene una existencia material entonces podemos resumir que para el tuyo la ideología puede ser general particular que no tiene historia que es eterna y que tiene una existencia material la relación imaginaria de los individuos con sus condiciones reales de existencia y los sujetos por propia voluntad se someten al orden vigente y a la ideología dominante el tercer autor con respecto a la ideología nos va a decir que es un sistema de representación es dotado de existencia material y un papel histórico determinado la diferencia del autor anterior va a hablar sobre instituciones y sobre fenómenos mentales y va a dar ciertos rasgos de las ideologías por un lado nos va a decir que son sistemas completos globalizantes ya que ofrece una visión del mundo total y por otro nos va a decir que son deformantes ya que se ocultan ciertos aspectos de la realidad para servir mejor a unos intereses particulares o existen varios sistemas de representaciones y son estabilizantes y portadoras de esperanzas bien en esta unidad vamos a ver también a tres autores el primero de ellos es fashion que va a tener algunos conceptos y términos que nos va a presentar de manera muy desarrollada y muy completa he aquí los términos más importantes y los más destacados y va a mencionar en un principio de la universalidad de la subordinación femenina de que la ideología patriarcal agudiza las formas de dominación y también va a mencionar algunos conceptos relacionados con el feminismo para decir que es un movimiento social y político para la liberación del sexo femenino va a mencionar algunos principios comunes del feminismo va a hablar sobre la jerarquización de las dicotomías la glorificación del lado femenino ya que por un lado los hombres exaltan a las mujeres y por otro lado la degradan va a decir que se tomó como referente al lado masculino y va a mencionar algunas instituciones del patriarcado como lo son el lenguaje la familia la educación androcéntrica la maternidad forzada la historia robada la heterosexualidad obligatoria las religiones el derecho y la violencia de género por su parte mafia va a mencionar los principios del feminismo que es descriptivo prescriptivo y práctico va a mencionar también las dicotomías la sexualización del par y la jerarquización del par va a ser un breve resumen sobre la historia del feminismo en la década de los 70 se buscaba la igualdad en la década del 80 la diferencia y en la década del 90 se critica todo lo anterior y también no mencionar la epistemología del feminismo por su parte el último autor márquez va a hablar sobre la sociedad patriarcal y va a hablar del varón como el ser importante el varón es el importante va a decir que el varón más mujer es igual a varón completo por eso hablar de complementariedad en el varón nos va a decir que la identidad de género es un espíritu de cuerpo va a hablar sobre el modelo imagen refugio de información y angustia y con respecto al amor masculinidad va a hablar sobre el varón en propiedad y el varón entró en precario y también nos va a hablar de la socialidad bien estos son los principales conceptos de este autor bueno estos son los principales conceptos de los tres autores que se ven en la unidad número 5 se espero que te sirva este este resumen si quieres recibir el resumen completo para aprobar el segundo parcial el resumen para el primer parcial o los dos solamente suscríbete a mi canal y dejar un comentario con tu dirección de email para poder recibir este resumen en formato pdf y sin ningún costo si quieres cualquier otro resumen o una clase particular lo que necesites solamente suscribirte y dejarme un comentario y lo podemos coordinar espero que tengas mucha suerte\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mfalcon/projects/chequeabot/cbot/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.24274341762065887,\n",
       " 'start': 8846,\n",
       " 'end': 8908,\n",
       " 'answer': 'el primero la industria racional la tradicional el carismático'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\n",
    "    {\n",
    "        'question': '¿Cuáles son los distintos tipos de dominación legítima? ',\n",
    "        'context': context\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mfalcon/projects/chequeabot/cbot/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.3397424519062042,\n",
       " 'start': 3588,\n",
       " 'end': 3626,\n",
       " 'answer': 'primera etapa de la vida de la persona'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\n",
    "    {\n",
    "        'question': '¿Cúando se da la socialización primaria? ',\n",
    "        'context': context\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff24090aeb304466ba23696ba0db6c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=573.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b6e5ad20e145ef96d321f539754198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=980988.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62cbc263daa0449ab669c549e8eb4dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=523071.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9525e016c44aa8a738888edd17f933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=150.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0327df8885d465e96df29eaba54e13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db387e087ac74d9f8df94d742adeee4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=506367455.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at mrm8488/RuPERTa-base-finetuned-pawsx-es were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/RuPERTa-base-finetuned-pawsx-es\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"mrm8488/RuPERTa-base-finetuned-pawsx-es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdfc8c9f91434cd4a820cda14e5d6b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=596.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68265e2270c492d911d67bb1dede422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=242120.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe62b3181f34e189cd7a001658887a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=112.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa7f055caf14be5aa099b2b8661625d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=62.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff809d0cc674604889b7682998e7e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=439495447.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer_b = AutoTokenizer.from_pretrained(\"mrm8488/electricidad-base-finetuned-pawsx-es\")\n",
    "model_b = AutoModelForSequenceClassification.from_pretrained(\"mrm8488/electricidad-base-finetuned-pawsx-es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should be paraphrase\n",
      "no son lo mismo: 19%\n",
      "son lo mismo: 81%\n",
      "\n",
      "Should not be paraphrase\n",
      "no son lo mismo: 66%\n",
      "son lo mismo: 34%\n"
     ]
    }
   ],
   "source": [
    "classes = [\"no son lo mismo\", \"son lo mismo\"]\n",
    "\n",
    "sequence_0 = \"La inflación en 2016 fue de 50%\"\n",
    "sequence_1 = \"En el 2016 tuvimos una inflación cercana al 50%\"\n",
    "sequence_2 = \"La inflación es un problema que Argentina no puede solucionar\"\n",
    "\n",
    "paraphrase = tokenizer.encode_plus(sequence_0, sequence_1, return_tensors=\"pt\")\n",
    "not_paraphrase = tokenizer.encode_plus(sequence_0, sequence_2, return_tensors=\"pt\")\n",
    "\n",
    "paraphrase_classification_logits = model(**paraphrase)[0]\n",
    "not_paraphrase_classification_logits = model(**not_paraphrase)[0]\n",
    "\n",
    "paraphrase_results = torch.softmax(paraphrase_classification_logits, dim=1).tolist()[0]\n",
    "not_paraphrase_results = torch.softmax(not_paraphrase_classification_logits, dim=1).tolist()[0]\n",
    "\n",
    "print(\"Should be paraphrase\")\n",
    "for i in range(len(classes)):\n",
    "    print(f\"{classes[i]}: {round(paraphrase_results[i] * 100)}%\")\n",
    "\n",
    "print(\"\\nShould not be paraphrase\")\n",
    "for i in range(len(classes)):\n",
    "    print(f\"{classes[i]}: {round(not_paraphrase_results[i] * 100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_pair = tokenizer.encode_plus(sequence_0, sequence_1, return_tensors=\"pt\")\n",
    "claims_pair_logits = model(**claims_pair)[0]\n",
    "claims_pair_results = torch.softmax(claims_pair_logits, dim=1).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no son lo mismo: 19%\n",
      "son lo mismo: 81%\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(classes)):\n",
    "    print(f\"{classes[i]}: {round(claims_pair_results[i] * 100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.18940554559230804, 0.8105944991111755]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claims_pair_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims = [\n",
    "    'La inflación en 2016 fue de 50%',\n",
    "    'En el 2016 tuvimos una inflación cercana al 50%',\n",
    "    'La inflación es un problema que Argentina no puede solucionar',\n",
    "    'En los 12 últimos meses la inflación fue la más baja de los últimos siete años.',\n",
    "    'Hay que trabajar medio año para el Estado.',\n",
    "    'Trabajamos la mitad del año para pagarle impuestos al Estado',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_claims = []\n",
    "for i in range(len(claims)):\n",
    "    for j in range(len(claims)):\n",
    "        if i == j:\n",
    "            continue\n",
    "        claims_pair = tokenizer.encode_plus(claims[i], claims[j], return_tensors=\"pt\")\n",
    "        claims_pair_logits = model(**claims_pair)[0]\n",
    "        claims_pair_results = torch.softmax(claims_pair_logits, dim=1).tolist()[0]\n",
    "        if claims_pair_results[1] > 0.7:\n",
    "            similar_claims.append([claims[i], claims[j], claims_pair_results[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_claims_b = []\n",
    "for i in range(len(claims)):\n",
    "    for j in range(len(claims)):\n",
    "        if i == j:\n",
    "            continue\n",
    "        claims_pair = tokenizer_b.encode_plus(claims[i], claims[j], return_tensors=\"pt\")\n",
    "        claims_pair_logits = model_b(**claims_pair)[0]\n",
    "        claims_pair_results = torch.softmax(claims_pair_logits, dim=1).tolist()[0]\n",
    "        if claims_pair_results[1] > 0.7:\n",
    "            similar_claims_b.append([claims[i], claims[j], claims_pair_results[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['La inflación en 2016 fue de 50%',\n",
       "  'En el 2016 tuvimos una inflación cercana al 50%',\n",
       "  0.8105944991111755],\n",
       " ['En el 2016 tuvimos una inflación cercana al 50%',\n",
       "  'La inflación en 2016 fue de 50%',\n",
       "  0.806519627571106],\n",
       " ['Trabajamos la mitad del año para pagarle impuestos al Estado',\n",
       "  'La inflación en 2016 fue de 50%',\n",
       "  0.7567902207374573],\n",
       " ['Trabajamos la mitad del año para pagarle impuestos al Estado',\n",
       "  'Hay que trabajar medio año para el Estado.',\n",
       "  0.721567690372467]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_claims"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
