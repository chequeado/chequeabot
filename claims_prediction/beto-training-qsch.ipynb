{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificaci√≥n de frases chequeables usando Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este problema se intentar√° usar [Beto](https://github.com/dccuchile/beto) y HuggingFace. Especialmente se sigue este [ejemplo](https://huggingface.co/transformers/custom_datasets.html#seq-imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "#!wget https://users.dcc.uchile.cl/~jperez/beto/cased_2M/pytorch_weights.tar.gz \n",
    "#!wget https://users.dcc.uchile.cl/~jperez/beto/cased_2M/vocab.txt \n",
    "#!wget https://users.dcc.uchile.cl/~jperez/beto/cased_2M/config.json \n",
    "#!tar -xzvf pytorch_weights.tar.gz\n",
    "#!mv config.json pytorch/.\n",
    "#!mv vocab.txt pytorch/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForMaskedLM, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at pytorch/ were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"pytorch/\", do_lower_case=False)\n",
    "model = BertForMaskedLM.from_pretrained(\"pytorch/\")\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASK 0 : ['ignorancia', 'guerra', 'pobreza', 'muerte', 'violencia']\n",
      "MASK 1 : ['pa√≠s', 'tiempo', 'pueblo', 'mundo', 'planeta']\n"
     ]
    }
   ],
   "source": [
    "text = \"[CLS] La [MASK] es el problema de nuestro [MASK] [SEP]\"\n",
    "masked_indxs = (2,8)\n",
    "\n",
    "tokens = tokenizer.tokenize(text)\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokens)\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "predictions = model(tokens_tensor)[0]\n",
    "\n",
    "for i,midx in enumerate(masked_indxs):\n",
    "    idxs = torch.argsort(predictions[0,midx], descending=True)\n",
    "    predicted_token = tokenizer.convert_ids_to_tokens(idxs[:5])\n",
    "    print('MASK',i,':',predicted_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from constants import POS_TAGGED_FOLDER\n",
    "\n",
    "\n",
    "def get_tagged_sentences(folder):\n",
    "    # Load all the tagged sentences included in the .pickle files \n",
    "    parsed_sentences = []\n",
    "    for filename in glob.glob(folder + '*.pickle'):\n",
    "        with open(filename, 'rb') as tagged_file:\n",
    "            parsed_sentences = parsed_sentences + pickle.load(tagged_file, encoding=\"bytes\")\n",
    "    return parsed_sentences\n",
    "\n",
    "tagged_sentences = get_tagged_sentences(POS_TAGGED_FOLDER)\n",
    "data = [{'sentence': item[b'sentence'].decode('utf8').lower(), 'target': item[b'classification'].decode('utf8')} for item in tagged_sentences]\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': '\\ufeffdiscurso de la presidenta cristina fern√°ndez de kirchner en la inauguracion del 133¬∞ periodo de sesiones ordinarias del congreso nacional',\n",
       " 'target': 'non-fact-checkable'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ôªødiscurso de la presidenta cristina fern√°ndez ...</td>\n",
       "      <td>non-fact-checkable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>muy buenos d√≠as a todos y todas</td>\n",
       "      <td>non-fact-checkable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vengo una vez m√°s a cumplir con lo dispuesto p...</td>\n",
       "      <td>non-fact-checkable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>y la verdad que quiero comenzar dando cuenta d...</td>\n",
       "      <td>non-fact-checkable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>el d√≠a viernes 27 pude leer un tuit en la cuen...</td>\n",
       "      <td>non-fact-checkable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence              target\n",
       "0  Ôªødiscurso de la presidenta cristina fern√°ndez ...  non-fact-checkable\n",
       "1                    muy buenos d√≠as a todos y todas  non-fact-checkable\n",
       "2  vengo una vez m√°s a cumplir con lo dispuesto p...  non-fact-checkable\n",
       "3  y la verdad que quiero comenzar dando cuenta d...  non-fact-checkable\n",
       "4  el d√≠a viernes 27 pude leer un tuit en la cuen...  non-fact-checkable"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-3ba6a057844a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m '''\n\u001b[1;32m     17\u001b[0m \u001b[0;31m###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m  \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'fact-checkable'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "'''\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(df, df['target']):\n",
    "    strat_train_set = df.loc[train_index]\n",
    "    strat_test_set = df.loc[test_index]\n",
    "\n",
    "train_texts = strat_train_set.drop(['target'], axis=1).astype(str)\n",
    "train_labels = strat_train_set['target'].values.tolist()\n",
    "\n",
    "test_texts = strat_test_set.drop(['target'], axis=1).values.tolist()\n",
    "test_labels = strat_test_set['target'].values.tolist()\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)\n",
    "'''\n",
    "###\n",
    "X = [e['sentence'] for e in data]\n",
    "y = [0  if e['target'] == 'fact-checkable' else 1 for e in data]\n",
    "\n",
    "sentences = [\"[CLS] \" + e['sentence'] + \" [SEP]\" for e in data]\n",
    "labels = [0  if e['target'] == 'fact-checkable' else 1 for e in data]\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(X, y, test_size=.2)\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['¬øpor qu√© protestan? les digo',\n",
       " 'por eso el gran desaf√≠o fue mantener pol√≠ticas p√∫blicas activas y aumentar las que ya hab√≠amos desplegado para precisamente poder superar toda esta crisis',\n",
       " 'stolbizer- creo posible y necesario establecer acuerdos',\n",
       " ' la rep√∫blica argentina es el √∫nico pa√≠s que ha descendido en forma negativa su deuda externa en todo el mundo',\n",
       " 'este adelanto en materia de transplante es tambi√©n patrimonio del parlamento argentino a partir de la aprobaci√≥n de la ley del donante presunto']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class ChqDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = ChqDataset(train_encodings, train_labels)\n",
    "val_dataset = ChqDataset(val_encodings, val_labels)\n",
    "test_dataset = ChqDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at pytorch/ were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at pytorch/ and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='775' max='775' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [775/775 04:12, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.680541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.680453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.620086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.559473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.583552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.521176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.452430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.367741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.369752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.361647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.346413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.384587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.234018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.341694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.352852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.176521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.175262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.281357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.184632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.363698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.192397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.196714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.273158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.329172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.253615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.193625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.152853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.287333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.336805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.151416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.202657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.043102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.182343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.107600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.196217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.100383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.200086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.082635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.233781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.154616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.320234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.183944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.144470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.152608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.184438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.183208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.079955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.022195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.086252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.116829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.054254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.064793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.143614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.263046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.117714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.057156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.264734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.175836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.078848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.078896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.003284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.019269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.019980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.025900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.046706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.016994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.009203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.011520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.003918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.002414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.004076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.048848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.043687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.001489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.000491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.000508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=775, training_loss=0.1933819776965726)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=5,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"pytorch/\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ü§ó Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset,             # evaluation dataset\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('qsch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='16' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 08:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.46729370951652527,\n",
       " 'eval_accuracy': 0.9142394822006472,\n",
       " 'eval_f1': 0.9284750337381916,\n",
       " 'eval_precision': 0.9373297002724795,\n",
       " 'eval_recall': 0.9197860962566845,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_texts = ['hay m√°s de 25 millones de trabajadores que est√°n registrados', \n",
    "              'hay m√°s de 50 millones de trabajadores que est√°n registrados', \n",
    "              'discurso de la presidenta cristina fern√°ndez de kirchner en la inauguracion del 133¬∞ periodo',\n",
    "             'vamos a otorgar un subsidio de 15 mil pesos por cada nuevo empleo registrado durante doce meses',\n",
    "              'prometo bajar la inflaci√≥n a un 10% en el 2021',\n",
    "             'se le saca a la Ciudad el 12% del presupuesto',\n",
    "             ]\n",
    "demo_labels = [0, 0, 1, 1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_encodings = tokenizer(demo_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(demo_encodings.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_dataset = ChqDataset(demo_encodings, demo_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 4.438871 , -3.965041 ],\n",
       "       [ 4.4410357, -3.9678428],\n",
       "       [-3.9221334,  3.6707048],\n",
       "       [ 2.477028 , -1.8974282],\n",
       "       [ 3.7844305, -3.4295647],\n",
       "       [ 4.4204555, -3.960571 ]], dtype=float32), label_ids=array([0, 0, 1, 1, 0, 0]), metrics={'eval_loss': 0.7314813137054443, 'eval_accuracy': 0.8333333333333334, 'eval_f1': 0.6666666666666666, 'eval_precision': 1.0, 'eval_recall': 0.5})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.predict(demo_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hay m√°s de 25 millones de trabajadores que est√°n registrados',\n",
       " 'hay m√°s de 50 millones de trabajadores que est√°n registrados',\n",
       " 'discurso de la presidenta cristina fern√°ndez de kirchner en la inauguracion del 133¬∞ periodo',\n",
       " 'vamos a otorgar un subsidio de 15 mil pesos por cada nuevo empleo registrado durante doce meses',\n",
       " 'se le saca a la Ciudad el 12% del presupuesto']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without labels\n",
    "class ChqInferenceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, total_items):\n",
    "        self.encodings = encodings\n",
    "        self.total_items = total_items\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        #item['labels'] = torch.tensor(self.labels[idx])\n",
    "        print(item)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-749d77a67c82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdemo_encodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdemo_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnolabel_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChqInferenceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdemo_encodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdemo_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnolabel_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "demo_encodings = tokenizer(demo_texts, truncation=True, padding=True)\n",
    "nolabel_dataset = ChqInferenceDataset(demo_encodings, len(demo_texts))\n",
    "output = trainer.predict(nolabel_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.3871017, -3.7961414],\n",
       "       [ 3.3651884, -3.7773092],\n",
       "       [-3.2432277,  3.7316933],\n",
       "       [-1.8270873,  3.0422065],\n",
       "       [ 3.815342 , -4.118779 ]], dtype=float32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secci√≥n de inferencia a partir de la carga del modelo pre-entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_classification = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"./qsch\",\n",
    "    tokenizer=\"dccuchile/bert-base-spanish-wwm-cased\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9992413520812988},\n",
       " {'label': 'LABEL_0', 'score': 0.9992098212242126},\n",
       " {'label': 'LABEL_1', 'score': 0.9990658760070801},\n",
       " {'label': 'LABEL_1', 'score': 0.9923797249794006},\n",
       " {'label': 'LABEL_0', 'score': 0.9988777041435242},\n",
       " {'label': 'LABEL_0', 'score': 0.9996417760848999},\n",
       " {'label': 'LABEL_1', 'score': 0.9501869082450867},\n",
       " {'label': 'LABEL_0', 'score': 0.9963929057121277},\n",
       " {'label': 'LABEL_1', 'score': 0.9972434639930725},\n",
       " {'label': 'LABEL_1', 'score': 0.985137403011322},\n",
       " {'label': 'LABEL_0', 'score': 0.9995606541633606},\n",
       " {'label': 'LABEL_1', 'score': 0.9986720085144043},\n",
       " {'label': 'LABEL_1', 'score': 0.999411404132843},\n",
       " {'label': 'LABEL_1', 'score': 0.9993310570716858},\n",
       " {'label': 'LABEL_1', 'score': 0.9992738366127014}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_claims = [\n",
    "    'hay m√°s de 25 millones de trabajadores que est√°n registrados', \n",
    "    'hay m√°s de 50 millones de trabajadores que est√°n registrados', \n",
    "    'discurso de la presidenta cristina fern√°ndez de kirchner en la inauguracion del 133¬∞ periodo',\n",
    "    'vamos a otorgar un subsidio de 15 mil pesos por cada nuevo empleo registrado durante doce meses',\n",
    "    'prometo bajar la inflaci√≥n a un 10% en el 2021',\n",
    "    'se le saca a la Ciudad el 12% del presupuesto',\n",
    "    'no es cierto que vamos a devaluar en enero',\n",
    "    'Guzm√°n est√° tomando deuda al 17%',\n",
    "    'La √∫nica posibilidad de Argentina de iniciar la recuperaci√≥n es crear las condiciones para impulsar la inversi√≥n, generadora de nuevos puestos de trabajo bajo reg√≠menes m√°s modernos y tan justos como los vigentes',\n",
    "    'Y cuando decimos que queremos bajar el d√©ficit a cuatro puntos y medio ‚Äìde los 9 que seguramente tendremos este a√±o‚Äì, nos llaman ajustadores',\n",
    "    'Hoy se consume la misma energ√≠a para producci√≥n industrial que se consum√≠a el 19 de marzo. Y el consumo es m√°s alto',\n",
    "    'Yo no comparto la mirada de muchos que dicen que esto es un ajuste sobre los jubilados porque en verdad se basa en dos puntos: la variaci√≥n de los salarios y la recaudaci√≥n, que es importante porque si no recaud√°s, no podemos pagar',\n",
    "    'Alberto qu√© recuerdos tienes de la √∫ltima vez que te visit√≥ Diego, en enero y cu√°l es el recuerdo del primer contacto que ten√©s con Diego.',\n",
    "    'Yo creo que, en verdad, todos los argentinos estamos en deuda con √©l, porque son esos hombres que‚Ä¶ bueno con vos pasa un poco lo mismo, son esos hombres que s√≥lo nos han dado alegr√≠a. ',\n",
    "    '¬øC√≥mo se hace ‚Äì Alberto - para convivir siendo el presidente de todos los argentinos, el hincha, el hombre com√∫n, en un momento para desempe√±ar tantos roles, porque por un lado hay una cosa del protocolo, pero surge el hincha, la emoci√≥n, del tipo com√∫n, c√≥mo se hace para manejar eso?',\n",
    "]\n",
    "text_classification(eval_claims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus track: test de un modelo de QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e33c695d125344c88f4937cc8e437787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=465.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38bccadd83e1477683a2e91f8965391e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=439457860.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0834fd9fd8254cf38731370f550d3486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=242349.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e15c39db10448a49c7f689390333284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=112.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e7421ac0f146bca945e3e5f8c1c145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=135.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nlp = pipeline(\n",
    "    'question-answering', \n",
    "    model='mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es',\n",
    "    tokenizer=(\n",
    "        'mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es',  \n",
    "        {\"use_fast\": False}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.youtube.com/watch?v=yA_IDTcoj-Q\n",
    "#lo pasamos por el desgrabador y obtenemos el siguiente texto\n",
    "context = r\"\"\"\n",
    "hoy vamos a dar la lecci√≥n 1 sociolog√≠a y vida cotidiana vamos a repasar los principales t√©rminos de los autores de la lecci√≥n 1 en primer lugar tenemos a m√°rquez donde los t√©rminos m√°s importantes lo que nosotros tenemos que destacar de este autor es que naturalizamos lo social es decir que tenemos una actitud irreflexiva frente a nuestras conductas cotidianas el segundo actor fue meals que nos habl√≥ de imaginaci√≥n sociol√≥gica que es la invasi√≥n de imaginaci√≥n sociol√≥gica bueno es una cualidad que permite comprender la relaci√≥n entre problema e inquietud y entre biograf√≠a e historia he aqu√≠ que tenemos los principales t√©rminos que tenemos que identificar de este autor en lo que respecta a la sociedad la historia de la sociedad y la biograf√≠a individual lo que es una inquietud y lo que es un problema recordemos que inquietud hace referencia a un asunto privado que ocupa a una sola persona y un problema es un asunto p√∫blico que refiere a varias personas por ejemplo el hecho del desempleo si una sola persona en la sociedad no tiene trabajo ese es un asunto privado es una inquietud pero si el 18 por ciento de la de las personas en edad laboral de una sociedad no tienen trabajo pasa a ser un asunto p√∫blico con respecto a el√≠as el√≠as va a hablar sobre las dificultades en nuestro idioma para pensar sociol√≥gicamente a trav√©s de la cosificaci√≥n que es una deshumanizaci√≥n de figuras sociales que nos lleva a la metaf√≠sica de esas figuras y que nuestro lenguaje est√° basado en un modelo de ciencias naturales y del pensamiento m√°gico m√≠tico y basado b√°sicamente en un modelo de voz c√©ntrico donde las fantas√≠as ocupan un lugar errado en la vida de los hombres y va a proponer el modelo de relaciones de interdependencia donde todos estamos conectados en la sociedad en el trabajo de la sociolog√≠a debe ser ampliar y hacer m√°s confiable la comprensi√≥n de los elementos o activos por su parte heller nos va a hablar de la vida cotidiana es decir la vida cotidiana es un conjunto de actividades que implican al mismo tiempo la reproducci√≥n individual y social es jer√°rquica por eso habla de un regimiento de la vida es heterog√©nea ya que es el ya que el medio de superaci√≥n a la particularidad es la homogenizaci√≥n y habla sobre el papel que juega la ultra generalizaci√≥n en nuestra vida cotidiana a trav√©s de los juicios provisionales y los prejuicios y va a mencionar tambi√©n la extra la extra√±a acci√≥n de la vida cotidiana que proviene de la cristalizaci√≥n de las caracter√≠sticas de la vida cotidiana que reducen el margen de movimiento y conciencia de los individuos va a mencionar tambi√©n la √©tica que tiene que sirve para el veto de ciertas conductas y tambi√©n para la transformaci√≥n quiere decir que el ser que las personas son al mismo tiempo particular y espec√≠fico el medio recordemos para de superaci√≥n de la particularidad hacia la especificidad es la homogenizaci√≥n de la vida cotidiana con respecto a berger y lukman van a ver la sociedad desde dos puntos de vista primero la sociedad como realidad objetiva hablar de la institucionalizaci√≥n va a decir que el orden social es un producto humano y aparece cada vez que se da una tipificaci√≥n rec√≠proca de acciones habitual izadas por tipos de actores esto hay que recordarlo es bastante importante con respecto a la institucionalizaci√≥n estos son los principales temas y puntos que tocan bergara bergara y luminosos principales conceptos institucionalizaci√≥n roles sedimentaci√≥n el legitimaci√≥n por otro lado la sociedad con realidad subjetiva va a hablar sobre la socializaci√≥n primaria que es la que se da en la primera etapa de la vida de la persona la socializaci√≥n secundaria que es la siguiente como es el mantenimiento y transformaci√≥n de la realidad y va a mencionar tambi√©n algo sobre las teor√≠as de la identidad edad 23 perspectivas sociol√≥gicas si quieres recibir el resumen completo tanto del primer parcial como del segundo o ambos para preparar el final solamente tienes que suscribirte a mi canal y dejarme un comentario para que te pueda enviar el email en formato pdf con este resumen vamos a comenzar tenemos tres auto autores en esta unidad n√∫mero dos el primero de ellos es urgen que va a hablar principalmente su punto central va a ser hecho social que es un hecho social y va a partir de la de la sociolog√≠a objetivista su sociolog√≠a va a ser objetivista porque tambi√©n porque exige que el soci√≥logo explique las causas externas que llevan a los individuos a actuar y que va a decir sobre un hecho social va a ser que son cosas va a hablar de corriente opini√≥n iba a hablar de que la realidad social es independiente de la voluntad de los individuos y en estos son los principales t√©rminos de este autor con respecto al segundo autor que se nos presenta en esta unidad que es marx que se puede profundizar mucho m√°s pero estos son sus principales t√©rminos que nos van a tomar en el examen el primero de ellos es la producci√≥n sobre la producci√≥n m√°s simples la producci√≥n es de individuos que en sociedad va a decir que el proceso de trabajo es natural y social y su principal termino con relaci√≥n la producci√≥n va a ser la plusval√≠a plusval√≠a tambi√©n va a hablar sobre consumo y producci√≥n sobre distribuci√≥n cambio y producci√≥n y sobre el capitalismo que va a decir que es un tipo de organizaci√≥n social cuyo objetivo es la acumulaci√≥n de riquezas y continua reproducci√≥n de capital y que la expansi√≥n e integraci√≥n constante del mercado exterior es una gran unidad econ√≥mica m√°s todo esto m√°s el creciente aumento de la productividad del trabajo por la permanente innovaci√≥n tecnol√≥gicos son los mecanismos que garantizan su continuidad ciclina e irving van a retomar el trabajo de marks y van a hablar van a mencionar precisamente estos t√©rminos van a hablar con respecto a la religi√≥n y las condiciones seculares principalmente del juda√≠smo y les va a decir que para evitar la discriminaci√≥n y la destrucci√≥n deben emanciparse del comercio del dinero y que las relaciones de propiedad es el punto de partida de la teor√≠a de clases beber por su parte va a hablar en esta en esta unidad principalmente de acci√≥n social la acusaci√≥n es una acci√≥n en donde encendido aumentado por su sujeto est√° referido a la conducta de otras personas a la voluntad de otros por eso es habla de un sentido subjetivo sentido subjetivo no toda clase de contacto entre personas entre hombres tiene car√°cter social y la acci√≥n social relacionado tambi√©n con lo que es dominaci√≥n va a decir que es racional con arreglo a fines racional con arreglo a valores afectiva o tradicional y el m√©todo de la sociolog√≠a comprensi√≥n es racionalista para medio ya que exige el soci√≥logo int√©rprete en sentido a partir del cual las personas orientan su acci√≥n bien vamos a esta unidad que es poder vamos a revisar a tres autores el primero de ellos al tu ser va a hablar del poder con respecto a la reproducci√≥n de las condiciones de producci√≥n primero hablar de la reproducci√≥n de los medios de producci√≥n a lo cual lo explica a vagamente y no le da demasiada importancia ya que es b√°sicamente la obtenci√≥n de los materiales para producir pero si le dan mayor importancia a la reproducci√≥n de las relaciones de producci√≥n existente y en la reproducci√≥n de las fuerzas productivas con respecto a la reproducci√≥n de las relaciones de producci√≥n existentes tenemos que decir que √©stas est√°n aseguradas por la acci√≥n de los aparatos de estado que terminan siendo relaciones de explotaci√≥n y con respecto a la reproducci√≥n de las fuerzas productivas en la reproducci√≥n de la fuerza de trabajo ser√° fuera de la empresa como a trav√©s del salario que le permite al trabajador vivir y satisfacer sus necesidades y a trav√©s de la calificaci√≥n laboral esta planificaci√≥n laboral son habilidades que se adquieren en el sistema educativo a trav√©s de los a√±os y principalmente la sumisi√≥n al sistema por su parte va a decir que el estado es un aparato represivo que permite a la clase dominante asegurar su dominaci√≥n sobre la clase trabajadora para someterlo al proceso de exploraci√≥n de la plusval√≠a como a trav√©s de los aparatos represivos del estado y los y del aparato ideol√≥gico del estado los aparatos represivos son por ejemplo la polic√≠a el ej√©rcito la administraci√≥n que funciona mediante la violencia de los aparatos ideol√≥gicos son por ejemplo la escuela la familia iglesia que funcionan mediante la ideolog√≠a bien estos son los principales t√©rminos principales conceptos de este autor en relaci√≥n al poder el segundo autor es beber el primero va a definir algunos t√©rminos que son importantes por ejemplo poder que es la imposici√≥n de la propia voluntad ya sea contra toda resistencia lo que es la dominaci√≥n la disciplina y la asociaci√≥n de dominaci√≥n ellos son b√°sicamente alguno de los principales t√©rminos que define ver quiero hablar son distintos tipos de dominaci√≥n leg√≠tima el primero la industria racional la tradicional el carism√°tico y nos va a decir que toda dominaci√≥n requiere de un cuadro administrativo el primer tipo de dominaci√≥n la dominaci√≥n racional tiene ciertas caracter√≠sticas que enumera por ejemplo un ejercicio continuado sujeto a la ley la competencia la jerarqu√≠a administrativa reglas t√©cnicas o normas y los funcionarios no son los propietarios de los medios materiales de administraci√≥n y tampoco existe la apropiaci√≥n de los cargos en el cuadro administrativo es un cuadro administrativo burocr√°tico con respecto a la dominaci√≥n tradicional nos va a decir que su legitimidad se basa en la santidad de ordenaciones y poderes de mando elevados de tiempos lejanos no se obedece a disposiciones sino a la persona los mandatos de las personas hoy leg√≠timo por la fuerza la tradici√≥n y son leg√≠timos por arbitrio libre del se√±or este tipo de dominaci√≥n se ve b√°sicamente monarqu√≠as y la dominaci√≥n carism√°tica en la que en la que mayor √©nfasis hace su estudio lo que es la que m√°s le interes√≥ a este autor este tipo de dominaci√≥n es decirle carisma es una cualidad extraordinaria y se la considera esta para la persona que ejerce este tipo de dominaci√≥n se la considera en posesi√≥n de fuerzas sobre humanas el reconocimiento se mantiene por corroboraci√≥n es decir aquel que ejerce el dominio de tipo carism√°tico debe mostrar que en verdad tiene estas fuerzas sobre humanas que generan el bienestar entro en todos los nominados el proceso de comunicaciones de car√°cter emotivo se opone a la dominaci√≥n tradicional y racional y el carisma puro es espec√≠ficamente extra√±o a la econom√≠a su cuadro administrativo est√° formado por servidores ligados a la autoridad en virtud de la lealtad personal y tiene un car√°cter extraordinario y revolucionario est√° este tipo de dominaci√≥n tambi√©n debe utilizarse debe racionalizarse ya que no se puede constantemente a ejercer este tipo de dominaci√≥n como se racionaliza bueno por inter√©s de la comunidad y por inter√©s del cuadro administrativo al mantener su posici√≥n en caso de que desaparezca la persona portadora de carisma se hace una nueva b√∫squeda por revelaci√≥n o por designaci√≥n hecha por el que portaba el carisma por una designaci√≥n echarle por el cuadro administrativo o se hace una b√∫squeda dentro de la familia en torno a los herederos de la persona carism√°tica ya que se relaciona con la sangre f√∫tbol por su parte cuando habla hable sobre poder nos va a decir que el sistema de poder de la monarqu√≠a excesivamente oneroso lo que hac√≠a que el poder pol√≠tico fuera muy discontinuo por ello la burgues√≠a y la monarqu√≠a instalaron una nueva forma de poder basada en el derecho donde ya no existe un solo poder sino que existen varios y el poder viene desde abajo y atraviesa toda relaci√≥n social surgen las t√©cnicas pol√≠ticas como la disciplina la educaci√≥n y el poder se ejerce en espacios cotidianos como la escuela una familia que se cambia la an√°tomo pol√≠tica por la videopol√≠tica lanata como pol√≠tica se ejerce sobre los cuerpos en cambio la vida pol√≠tica se ejerce sobre la poblaci√≥n la primera de ellas prescribe a partir de nuevas preexistentes las segundas reglas y normas fijadas y el poder deja de ser jur√≠dico para hacer materialista va a hablar tambi√©n sobre la delincuencia que tiene para este autor posee utilidad econ√≥mica y el peligro interno es una de las condiciones de aceptabilidad del control vamos a ver los autores que se nos presentan en la unidad 4 el primero de ellos es le fevre con respecto a la ideolog√≠a va a decirnos que es un reflejo invertido mutilado y deformado de lo real va a hablar tambi√©n de la praxis donde intervienen mediante las mediante la cooperaci√≥n y persuasi√≥n se convierte en el lenguaje y legitima las relaciones del poder esto es lo que nos dice con respecto a ideolog√≠as y estos son los principales conceptos que tenemos que tener en cuenta ideolog√≠a y praxis y la ideolog√≠a tiene un car√°cter doble por un lado son generales y especulativas y por otro lado representan intereses particulares con respecto al primer car√°cter general y especulativas en este lugar y act√∫a la coerci√≥n y la persuasi√≥n y se puede observar la transparencia de la ideolog√≠a en segundo lugar cuando la iv de la gente presente intereses particulares se asume la parte de la debilidad humana y se ve la opacidad de la ideolog√≠a el segundo autor alto observ√≥ hablar sobre ideolog√≠a general e ideolog√≠as particulares va a ser esta distinci√≥n de la ideolog√≠a general nos va a decir que no tiene historia que es eterna y nos va a decir que hay una garant√≠a de que todo est√° bien como est√° con la condici√≥n de que los sujetos reconozcan lo que son y se conduzcan en consecuencia con respeto energ√≠a particular no hace que tiene una existencia material entonces podemos resumir que para el tuyo la ideolog√≠a puede ser general particular que no tiene historia que es eterna y que tiene una existencia material la relaci√≥n imaginaria de los individuos con sus condiciones reales de existencia y los sujetos por propia voluntad se someten al orden vigente y a la ideolog√≠a dominante el tercer autor con respecto a la ideolog√≠a nos va a decir que es un sistema de representaci√≥n es dotado de existencia material y un papel hist√≥rico determinado la diferencia del autor anterior va a hablar sobre instituciones y sobre fen√≥menos mentales y va a dar ciertos rasgos de las ideolog√≠as por un lado nos va a decir que son sistemas completos globalizantes ya que ofrece una visi√≥n del mundo total y por otro nos va a decir que son deformantes ya que se ocultan ciertos aspectos de la realidad para servir mejor a unos intereses particulares o existen varios sistemas de representaciones y son estabilizantes y portadoras de esperanzas bien en esta unidad vamos a ver tambi√©n a tres autores el primero de ellos es fashion que va a tener algunos conceptos y t√©rminos que nos va a presentar de manera muy desarrollada y muy completa he aqu√≠ los t√©rminos m√°s importantes y los m√°s destacados y va a mencionar en un principio de la universalidad de la subordinaci√≥n femenina de que la ideolog√≠a patriarcal agudiza las formas de dominaci√≥n y tambi√©n va a mencionar algunos conceptos relacionados con el feminismo para decir que es un movimiento social y pol√≠tico para la liberaci√≥n del sexo femenino va a mencionar algunos principios comunes del feminismo va a hablar sobre la jerarquizaci√≥n de las dicotom√≠as la glorificaci√≥n del lado femenino ya que por un lado los hombres exaltan a las mujeres y por otro lado la degradan va a decir que se tom√≥ como referente al lado masculino y va a mencionar algunas instituciones del patriarcado como lo son el lenguaje la familia la educaci√≥n androc√©ntrica la maternidad forzada la historia robada la heterosexualidad obligatoria las religiones el derecho y la violencia de g√©nero por su parte mafia va a mencionar los principios del feminismo que es descriptivo prescriptivo y pr√°ctico va a mencionar tambi√©n las dicotom√≠as la sexualizaci√≥n del par y la jerarquizaci√≥n del par va a ser un breve resumen sobre la historia del feminismo en la d√©cada de los 70 se buscaba la igualdad en la d√©cada del 80 la diferencia y en la d√©cada del 90 se critica todo lo anterior y tambi√©n no mencionar la epistemolog√≠a del feminismo por su parte el √∫ltimo autor m√°rquez va a hablar sobre la sociedad patriarcal y va a hablar del var√≥n como el ser importante el var√≥n es el importante va a decir que el var√≥n m√°s mujer es igual a var√≥n completo por eso hablar de complementariedad en el var√≥n nos va a decir que la identidad de g√©nero es un esp√≠ritu de cuerpo va a hablar sobre el modelo imagen refugio de informaci√≥n y angustia y con respecto al amor masculinidad va a hablar sobre el var√≥n en propiedad y el var√≥n entr√≥ en precario y tambi√©n nos va a hablar de la socialidad bien estos son los principales conceptos de este autor bueno estos son los principales conceptos de los tres autores que se ven en la unidad n√∫mero 5 se espero que te sirva este este resumen si quieres recibir el resumen completo para aprobar el segundo parcial el resumen para el primer parcial o los dos solamente suscr√≠bete a mi canal y dejar un comentario con tu direcci√≥n de email para poder recibir este resumen en formato pdf y sin ning√∫n costo si quieres cualquier otro resumen o una clase particular lo que necesites solamente suscribirte y dejarme un comentario y lo podemos coordinar espero que tengas mucha suerte\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mfalcon/projects/chequeabot/cbot/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.24274341762065887,\n",
       " 'start': 8846,\n",
       " 'end': 8908,\n",
       " 'answer': 'el primero la industria racional la tradicional el carism√°tico'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\n",
    "    {\n",
    "        'question': '¬øCu√°les son los distintos tipos de dominaci√≥n leg√≠tima? ',\n",
    "        'context': context\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mfalcon/projects/chequeabot/cbot/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.3397424519062042,\n",
       " 'start': 3588,\n",
       " 'end': 3626,\n",
       " 'answer': 'primera etapa de la vida de la persona'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\n",
    "    {\n",
    "        'question': '¬øC√∫ando se da la socializaci√≥n primaria? ',\n",
    "        'context': context\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff24090aeb304466ba23696ba0db6c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=573.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b6e5ad20e145ef96d321f539754198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=980988.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62cbc263daa0449ab669c549e8eb4dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=523071.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9525e016c44aa8a738888edd17f933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=150.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0327df8885d465e96df29eaba54e13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db387e087ac74d9f8df94d742adeee4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=506367455.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at mrm8488/RuPERTa-base-finetuned-pawsx-es were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/RuPERTa-base-finetuned-pawsx-es\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"mrm8488/RuPERTa-base-finetuned-pawsx-es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdfc8c9f91434cd4a820cda14e5d6b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=596.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68265e2270c492d911d67bb1dede422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=242120.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe62b3181f34e189cd7a001658887a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=112.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa7f055caf14be5aa099b2b8661625d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=62.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff809d0cc674604889b7682998e7e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=439495447.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer_b = AutoTokenizer.from_pretrained(\"mrm8488/electricidad-base-finetuned-pawsx-es\")\n",
    "model_b = AutoModelForSequenceClassification.from_pretrained(\"mrm8488/electricidad-base-finetuned-pawsx-es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should be paraphrase\n",
      "no son lo mismo: 19%\n",
      "son lo mismo: 81%\n",
      "\n",
      "Should not be paraphrase\n",
      "no son lo mismo: 66%\n",
      "son lo mismo: 34%\n"
     ]
    }
   ],
   "source": [
    "classes = [\"no son lo mismo\", \"son lo mismo\"]\n",
    "\n",
    "sequence_0 = \"La inflaci√≥n en 2016 fue de 50%\"\n",
    "sequence_1 = \"En el 2016 tuvimos una inflaci√≥n cercana al 50%\"\n",
    "sequence_2 = \"La inflaci√≥n es un problema que Argentina no puede solucionar\"\n",
    "\n",
    "paraphrase = tokenizer.encode_plus(sequence_0, sequence_1, return_tensors=\"pt\")\n",
    "not_paraphrase = tokenizer.encode_plus(sequence_0, sequence_2, return_tensors=\"pt\")\n",
    "\n",
    "paraphrase_classification_logits = model(**paraphrase)[0]\n",
    "not_paraphrase_classification_logits = model(**not_paraphrase)[0]\n",
    "\n",
    "paraphrase_results = torch.softmax(paraphrase_classification_logits, dim=1).tolist()[0]\n",
    "not_paraphrase_results = torch.softmax(not_paraphrase_classification_logits, dim=1).tolist()[0]\n",
    "\n",
    "print(\"Should be paraphrase\")\n",
    "for i in range(len(classes)):\n",
    "    print(f\"{classes[i]}: {round(paraphrase_results[i] * 100)}%\")\n",
    "\n",
    "print(\"\\nShould not be paraphrase\")\n",
    "for i in range(len(classes)):\n",
    "    print(f\"{classes[i]}: {round(not_paraphrase_results[i] * 100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_pair = tokenizer.encode_plus(sequence_0, sequence_1, return_tensors=\"pt\")\n",
    "claims_pair_logits = model(**claims_pair)[0]\n",
    "claims_pair_results = torch.softmax(claims_pair_logits, dim=1).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no son lo mismo: 19%\n",
      "son lo mismo: 81%\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(classes)):\n",
    "    print(f\"{classes[i]}: {round(claims_pair_results[i] * 100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.18940554559230804, 0.8105944991111755]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claims_pair_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims = [\n",
    "    'La inflaci√≥n en 2016 fue de 50%',\n",
    "    'En el 2016 tuvimos una inflaci√≥n cercana al 50%',\n",
    "    'La inflaci√≥n es un problema que Argentina no puede solucionar',\n",
    "    'En los 12 √∫ltimos meses la inflaci√≥n fue la m√°s baja de los √∫ltimos siete a√±os.',\n",
    "    'Hay que trabajar medio a√±o para el Estado.',\n",
    "    'Trabajamos la mitad del a√±o para pagarle impuestos al Estado',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_claims = []\n",
    "for i in range(len(claims)):\n",
    "    for j in range(len(claims)):\n",
    "        if i == j:\n",
    "            continue\n",
    "        claims_pair = tokenizer.encode_plus(claims[i], claims[j], return_tensors=\"pt\")\n",
    "        claims_pair_logits = model(**claims_pair)[0]\n",
    "        claims_pair_results = torch.softmax(claims_pair_logits, dim=1).tolist()[0]\n",
    "        if claims_pair_results[1] > 0.7:\n",
    "            similar_claims.append([claims[i], claims[j], claims_pair_results[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_claims_b = []\n",
    "for i in range(len(claims)):\n",
    "    for j in range(len(claims)):\n",
    "        if i == j:\n",
    "            continue\n",
    "        claims_pair = tokenizer_b.encode_plus(claims[i], claims[j], return_tensors=\"pt\")\n",
    "        claims_pair_logits = model_b(**claims_pair)[0]\n",
    "        claims_pair_results = torch.softmax(claims_pair_logits, dim=1).tolist()[0]\n",
    "        if claims_pair_results[1] > 0.7:\n",
    "            similar_claims_b.append([claims[i], claims[j], claims_pair_results[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['La inflaci√≥n en 2016 fue de 50%',\n",
       "  'En el 2016 tuvimos una inflaci√≥n cercana al 50%',\n",
       "  0.8105944991111755],\n",
       " ['En el 2016 tuvimos una inflaci√≥n cercana al 50%',\n",
       "  'La inflaci√≥n en 2016 fue de 50%',\n",
       "  0.806519627571106],\n",
       " ['Trabajamos la mitad del a√±o para pagarle impuestos al Estado',\n",
       "  'La inflaci√≥n en 2016 fue de 50%',\n",
       "  0.7567902207374573],\n",
       " ['Trabajamos la mitad del a√±o para pagarle impuestos al Estado',\n",
       "  'Hay que trabajar medio a√±o para el Estado.',\n",
       "  0.721567690372467]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_claims"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
